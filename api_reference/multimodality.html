<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>KV Caching for Multimodal Models with vLLM | LMCache</title>
<meta content="KV Caching for Multimodal Models with vLLM | LMCache" property="og:title"/>
<meta content="KV Caching for Multimodal Models with vLLM | LMCache" name="twitter:title"/>
<link href="../_static/pygments.css?v=935426dd" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=42baaae4" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinxcontrib-images/LightBox2/lightbox2/dist/css/lightbox.min.css?v=6e7d0de0" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinxcontrib-images/LightBox2/lightbox2-customize/pointer.css?v=c97663ff" rel="stylesheet" type="text/css"/>
<link href="../_static/custom.css?v=0f06b6ab" rel="stylesheet" type="text/css"/>
<link href="../_static/scroll.css?v=d15ffde1" rel="stylesheet" type="text/css"/>
<link href="../_static/lmcache-logo.png" rel="icon"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../community/meetings.html" rel="next" title="Community meetings"/>
<link href="dynamic_connector.html" rel="prev" title="vLLM Dynamic Connector"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">LMCache</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/LMCache/LMCache/" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223                 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412                 -3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232                  3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474                 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24                  44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" aria-label="Color theme switcher" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../index.html"><span class="font-bold text-clip whitespace-nowrap">LMCache</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Welcome to LMCache</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Welcome to LMCache!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quickstart.html">Quickstart</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../getting_started/quickstart/index.html">More Examples<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../getting_started/quickstart/offload_kv_cache.html">Example: Offload KV cache to CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started/quickstart/share_kv_cache.html">Example: Share KV cache across multiple LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started/quickstart/disaggregated_prefill.html">Example: Disaggregated prefill</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started/quickstart/multimodality.html">Example: Multimodal KV Cache Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/kv_cache_calculator.html">KV Cache Size Calculator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/troubleshoot.html">TroubleShoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache offloading and sharing</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../kv_cache/storage_backends/index.html">Using Different Storage Backends<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/cpu_ram.html">CPU RAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/local_storage.html">Local storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/gds.html">GDS Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/redis.html">Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/s3.html">S3 Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/infinistore.html">InfiniStore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/mooncake.html">Mooncake</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/valkey.html">ValKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/weka.html">Weka</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/nixl.html">Nixl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache/storage_backends/external_backend.html">Configurable Storage Backends</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../kv_cache/caching_policies.html">Using Different Caching Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kv_cache/p2p_sharing.html">P2P KV Cache Sharing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Disaggregated prefill</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../disaggregated_prefill/nixl/index.html">Using NIXL<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../disaggregated_prefill/nixl/1p1d.html">1p1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../disaggregated_prefill/nixl/xpyd.html">XpYd</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../disaggregated_prefill/shared_storage.html">Using shared storage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache management</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../kv_cache_management/index.html">LMCache Controller<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/clear.html">Clear the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/compress.html">Compress and Decompress the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/health.html">Check controller health</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/lookup.html">Lookup the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/move.html">Move the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/pin.html">Pin the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_management/check_finish.html">Check finish of a control event</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache Optimizations</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../kv_cache_optimizations/compression/index.html">Compression<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../kv_cache_optimizations/compression/cachegen.html">CacheGen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../kv_cache_optimizations/blending.html">Blending</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kv_cache_optimizations/layerwise.html">Layerwise KV Transfer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use LMCache in production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../production/docker_deployment.html">Docker deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../production/kubernetes_deployment.html">Kubernetes deployment</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../production/observability/index.html">Observability<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../production/observability/vllm_endpoint.html">Metrics by vLLM API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../production/observability/internal_api_server.html">Internal API Server Metrics</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internal API Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal_api_server/internal_api_server.html">Configuring the Internal API Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internal_api_server/internal_api_server.html#how-to-extend-the-internal-api-server">How to extend the Internal API Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/docker_file.html">Dockerfile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/architecture.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/integration.html">Integration</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../developer_guide/extending_lmcache/index.html">Extending LMCache<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../developer_guide/extending_lmcache/plugin.html">Extending LMCache: Plugin</a></li>
</ul>
</li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../developer_guide/usage/index.html">Usage Data Module<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../developer_guide/usage/usage_stats_collection.html">Usage Stats Collection</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="configurations.html">Configuring LMCache</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage_backends.html">Adding new storage backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_connector.html">vLLM Dynamic Connector</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">KV Caching for Multimodal Models with vLLM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/meetings.html">Community meetings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/blogs.html">Blogs</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">LMCache</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">KV Caching for Multimodal Models with vLLM</span>
</nav>
<div id="content" role="main">
<section id="kv-caching-for-multimodal-models-with-vllm">
<h1>KV Caching for Multimodal Models with vLLM<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#kv-caching-for-multimodal-models-with-vllm"><span>#</span></a></h1>
<section id="overview">
<h2>Overview<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#overview" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#overview'"><span>#</span></a></h2>
<p>vLLM is building on its multimodal capability and currently supports the following <a class="reference external" href="https://docs.vllm.ai/en/latest/models/supported_models.html#list-of-multimodal-language-models">List of Multimodal Language Models</a>.</p>
<p>LMCache can therefore be used to speed up inference time for all multimodal models supported by vLLM. This document shows the speedup improvements using LMCache for KV caching in vLLM for multimodal models.</p>
<section id="examples-of-ttft-speed-up-for-different-multimodal-types">
<h3>Examples of TTFT speed up for different multimodal types<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#examples-of-ttft-speed-up-for-different-multimodal-types" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#examples-of-ttft-speed-up-for-different-multimodal-types'"><span>#</span></a></h3>
<section id="prerequisites">
<h4>Prerequisites<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#prerequisites"><span>#</span></a></h4>
<ul class="simple">
<li><p>A Machine with at least one GPU. You can adjust the max model length of your vLLM instance depending on your GPU memory</p></li>
<li><p>vLLM and LMCache installed (<a class="reference internal" href="../getting_started/installation.html"><span class="doc">Installation Guide</span></a>)</p></li>
<li><p>vLLM audio dependencies installed: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">vllm[audio]</span></code></p></li>
</ul>
</section>
<section id="examples">
<h4>Examples<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#examples"><span>#</span></a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The examples below use a python script for inferencing multimodal models hosted by vLLM.
The script is the <a class="reference external" href="https://github.com/vllm-project/vllm/blob/main/examples/online_serving/openai_chat_completion_client_for_multimodal.py">openai_chat_completion_client_for_multimodal python script in vLLM</a>.
You will need to download it locally for running the examples below.
The script is printed in the <a class="reference external" href="#reference-inferencing-multimodal-models-in-vllm-example-python-script">reference section</a> that follows for you perusal.
Go to the <a class="reference external" href="#example-output">Example output</a> section to see the output in the vLLM logs that demonstrate the speedup improvements.</p>
</div>
<section id="audio-inference-with-ultravox">
<h5>Audio Inference with Ultravox:<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#audio-inference-with-ultravox"><span>#</span></a></h5>
<p>Start vLLM server with <code class="docutils literal notranslate"><span class="pre">fixie-ai/ultravox-v0_5-llama-3_2-1b</span></code> model and LMCache KV caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">vllm<span class="w"> </span>serve<span class="w"> </span>fixie-ai/ultravox-v0_5-llama-3_2-1b<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">    </span>--max-model-len<span class="w"> </span><span class="m">4096</span><span class="w"> </span>--trust-remote-code<span class="w"> </span><span class="se">\</span>
</span><span id="line-3"><span class="w">    </span>--kv-transfer-config<span class="w"> </span><span class="s1">'{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'</span>
</span></code></pre></div>
</div>
<p>Run the python script twice to demonstrate TTFT speedup on the second turn because of the caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># run twice to see TTFT speedup</span>
</span><span id="line-2">python<span class="w"> </span>openai_chat_completion_client_for_multimodal.py<span class="w"> </span>--chat-type<span class="w"> </span>audio
</span></code></pre></div>
</div>
</section>
<section id="single-image-inference-with-llava">
<h5>Single Image Inference with Llava:<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#single-image-inference-with-llava"><span>#</span></a></h5>
<p>Start vLLM server with <code class="docutils literal notranslate"><span class="pre">llava-hf/llava-1.5-7b-hf</span></code> model and LMCache KV caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">vllm<span class="w"> </span>serve<span class="w"> </span>llava-hf/llava-1.5-7b-hf<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">    </span>--kv-transfer-config<span class="w"> </span><span class="s1">'{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'</span>
</span></code></pre></div>
</div>
<p>Run the python script twice to demonstrate TTFT speedup on the second turn because of the caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># run twice to see TTFT speedup</span>
</span><span id="line-2">python<span class="w"> </span>openai_chat_completion_client_for_multimodal.py<span class="w"> </span>--chat-type<span class="w"> </span>single-image
</span></code></pre></div>
</div>
</section>
<section id="multi-image-inference-with-phi-3-5-vision-instruct">
<h5>Multi-image Inference with Phi-3.5-vision-instruct:<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#multi-image-inference-with-phi-3-5-vision-instruct"><span>#</span></a></h5>
<p>Start vLLM server with <code class="docutils literal notranslate"><span class="pre">microsoft/Phi-3.5-vision-instruct</span></code> model and LMCache KV caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">vllm<span class="w"> </span>serve<span class="w"> </span>microsoft/Phi-3.5-vision-instruct<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">    </span>--trust-remote-code<span class="w"> </span>--max-model-len<span class="w"> </span><span class="m">4096</span><span class="w"> </span>--limit-mm-per-prompt<span class="w"> </span><span class="s1">'{"image":2}'</span><span class="w"> </span><span class="se">\</span>
</span><span id="line-3"><span class="w">    </span>--kv-transfer-config<span class="w"> </span><span class="s1">'{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'</span>
</span></code></pre></div>
</div>
<p>Run the python script twice to demonstrate TTFT speedup on the second turn because of the caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># run twice to see TTFT speedup</span>
</span><span id="line-2">python<span class="w"> </span>openai_chat_completion_client_for_multimodal.py<span class="w"> </span>--chat-type<span class="w"> </span>multi-image
</span></code></pre></div>
</div>
</section>
<section id="video-inference-with-llava-onevision">
<h5>Video Inference with Llava-OneVision:<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#video-inference-with-llava-onevision"><span>#</span></a></h5>
<p>Start vLLM server with <code class="docutils literal notranslate"><span class="pre">llava-hf/llava-onevision-qwen2-7b-ov-hf</span></code> model and LMCache KV caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">vllm<span class="w"> </span>serve<span class="w"> </span>llava-hf/llava-onevision-qwen2-7b-ov-hf<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">    </span>--kv-transfer-config<span class="w"> </span><span class="s1">'{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'</span>
</span></code></pre></div>
</div>
<p>Run the python script twice to demonstrate TTFT speedup on the second turn because of the caching:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># run twice to see TTFT speedup</span>
</span><span id="line-2">python<span class="w"> </span>openai_chat_completion_client_for_multimodal.py<span class="w"> </span>--chat-type<span class="w"> </span>video
</span></code></pre></div>
</div>
</section>
</section>
<section id="id1">
<h4>Example output<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#id1"><span>#</span></a></h4>
<p>When running the examples above you will notice output in the vLLM logs similar to below.</p>
<p>This first output demonstrates the tokens being cached and loaded.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">[2025-08-04 22:43:35,484] LMCache INFO: Reqid: chatcmpl-05e2d296601046b29210f53a1fa30b13, Total tokens 1536, LMCache hit tokens: 1536, need to load: 1535 (vllm_v1_adapter.py:803:lmcache.integration.vllm.vllm_v1_adapter)
</span></code></pre></div>
</div>
<p>This then shows the speedup between the first and second runs.</p>
<ol class="arabic simple">
<li><p>First request:</p></li>
</ol>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Chat completion output from input audio: It seems like you're excitedly sharing your thoughts and predictions about a game you're about to watch. The audio appears to be a stream of comments or a social media post. The words "one pitch on the way to Edgar Martinez" suggest that someone is saying something in a baseball chat or social media post about the
</span><span id="line-2">Chat completion output from audio url: It appears to be a enthusiastic and excited baseball comment from an individual. The content seems to be a play-by-play description of a specific baseball game, with the narrator belonging to a team that is competing in the American League Championship Series. The reference to the player Edgar Martinez is a nod to a well-known baseball player,
</span><span id="line-3">Chat completion output from base64 encoded audio: It seems like you're excited about a baseball game, possibly the Los Angeles Dodgers or the Boston Red Sox, but it's unclear which one. The text mentions a "pitcher" and "swung on the line," but it's not entirely obvious which team it's referring to.
</span><span id="line-4">
</span><span id="line-5">However, the mention of "
</span><span id="line-6">Time taken: 50.828808307647705 seconds
</span></code></pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Second request:</p></li>
</ol>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Chat completion output from input audio: It seems like you're extremely excited about the possibility of the San Francisco Giants winning the American League championship and playing in the World Series. The audio is filled with emotions and a sense of optimism, with you enthusiastically expressing your thoughts and feelings. It's clear that this is a significant moment for you, particularly given the fact
</span><span id="line-2">Chat completion output from audio url: I can tell you're excited about a baseball game. It seems like you're reliving a moment during the middle of a game, especially the highlight of a six runs game for the Golden Giants. The audio appears to include a local sports radio talk show style broadcast, with a ringer ("the guy" in the
</span><span id="line-3">Chat completion output from base64 encoded audio: It seems like you're having a lively discussion about a Major League Baseball game, specifically about the shortstop playing for the Mariners and,Mario Upton swinging at a pitch and eventually being thrown out on a play at the plate. The atmosphere is excited, with all the cheering and commentary you've written. It appears to
</span><span id="line-4">Time taken: 3.3407371044158936 seconds
</span></code></pre></div>
</div>
</section>
</section>
<section id="reference-inferencing-multimodal-models-in-vllm-example-python-script">
<h3>Reference: Inferencing multimodal models in vLLM example Python script<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#reference-inferencing-multimodal-models-in-vllm-example-python-script" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#reference-inferencing-multimodal-models-in-vllm-example-python-script'"><span>#</span></a></h3>
<p>Source: <a class="reference external" href="https://github.com/vllm-project/vllm/blob/main/examples/online_serving/openai_chat_completion_client_for_multimodal.py">https://github.com/vllm-project/vllm/blob/main/examples/online_serving/openai_chat_completion_client_for_multimodal.py</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
</span><span id="line-2"><span class="c1"># SPDX-FileCopyrightText: Copyright contributors to the vLLM project</span>
</span><span id="line-3">
</span><span id="line-4"><span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
</span><span id="line-5">
</span><span id="line-6"><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
</span><span id="line-7"><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
</span><span id="line-8">
</span><span id="line-9"><span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
</span><span id="line-10">
</span><span id="line-11"><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
</span><span id="line-12"><span class="c1"># SPDX-FileCopyrightText: Copyright contributors to the vLLM project</span>
</span><span id="line-13"><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">APIConnectionError</span><span class="p">,</span> <span class="n">OpenAI</span>
</span><span id="line-14"><span class="kn">from</span><span class="w"> </span><span class="nn">openai.pagination</span><span class="w"> </span><span class="kn">import</span> <span class="n">SyncPage</span>
</span><span id="line-15"><span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
</span><span id="line-16">
</span><span id="line-17"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="line-18">
</span><span id="line-19">
</span><span id="line-20"><span class="k">def</span><span class="w"> </span><span class="nf">get_first_model</span><span class="p">(</span><span class="n">client</span><span class="p">:</span> <span class="n">OpenAI</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="line-21"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-22"><span class="sd">    Get the first model from the vLLM server.</span>
</span><span id="line-23"><span class="sd">    """</span>
</span><span id="line-24">    <span class="k">try</span><span class="p">:</span>
</span><span id="line-25">        <span class="n">models</span><span class="p">:</span> <span class="n">SyncPage</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
</span><span id="line-26">    <span class="k">except</span> <span class="n">APIConnectionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="line-27">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="line-28">            <span class="s2">"Failed to get the list of models from the vLLM server at "</span>
</span><span id="line-29">            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">client</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s2"> with API key </span><span class="si">{</span><span class="n">client</span><span class="o">.</span><span class="n">api_key</span><span class="si">}</span><span class="s2">. Check</span><span class="se">\n</span><span class="s2">"</span>
</span><span id="line-30">            <span class="s2">"1. the server is running</span><span class="se">\n</span><span class="s2">"</span>
</span><span id="line-31">            <span class="s2">"2. the server URL is correct</span><span class="se">\n</span><span class="s2">"</span>
</span><span id="line-32">            <span class="s2">"3. the API key is correct"</span>
</span><span id="line-33">        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="line-34">
</span><span id="line-35">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="line-36">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No models found on the vLLM server at </span><span class="si">{</span><span class="n">client</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="line-37">
</span><span id="line-38">    <span class="k">return</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span>
</span><span id="line-39">
</span><span id="line-40"><span class="c1"># Modify OpenAI's API key and API base to use vLLM's API server.</span>
</span><span id="line-41"><span class="n">openai_api_key</span> <span class="o">=</span> <span class="s2">"EMPTY"</span>
</span><span id="line-42"><span class="n">openai_api_base</span> <span class="o">=</span> <span class="s2">"http://localhost:8000/v1"</span>
</span><span id="line-43">
</span><span id="line-44"><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
</span><span id="line-45">    <span class="c1"># defaults to os.environ.get("OPENAI_API_KEY")</span>
</span><span id="line-46">    <span class="n">api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
</span><span id="line-47">    <span class="n">base_url</span><span class="o">=</span><span class="n">openai_api_base</span><span class="p">,</span>
</span><span id="line-48"><span class="p">)</span>
</span><span id="line-49">
</span><span id="line-50">
</span><span id="line-51"><span class="k">def</span><span class="w"> </span><span class="nf">encode_base64_content_from_url</span><span class="p">(</span><span class="n">content_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="line-52"><span class="w">    </span><span class="sd">"""Encode a content retrieved from a remote url to base64 format."""</span>
</span><span id="line-53">
</span><span id="line-54">    <span class="k">with</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">content_url</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
</span><span id="line-55">        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
</span><span id="line-56">        <span class="n">result</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
</span><span id="line-57">
</span><span id="line-58">    <span class="k">return</span> <span class="n">result</span>
</span><span id="line-59">
</span><span id="line-60">
</span><span id="line-61"><span class="c1"># Text-only inference</span>
</span><span id="line-62"><span class="k">def</span><span class="w"> </span><span class="nf">run_text_only</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-63">    <span class="n">chat_completion</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-64">        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"What's the capital of France?"</span><span class="p">}],</span>
</span><span id="line-65">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-66">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-67">    <span class="p">)</span>
</span><span id="line-68">
</span><span id="line-69">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-70">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-71">
</span><span id="line-72">
</span><span id="line-73"><span class="c1"># Single-image input inference</span>
</span><span id="line-74"><span class="k">def</span><span class="w"> </span><span class="nf">run_single_image</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-75">    <span class="c1">## Use image url in the payload</span>
</span><span id="line-76">    <span class="n">image_url</span> <span class="o">=</span> <span class="s2">"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"</span>
</span><span id="line-77">    <span class="n">chat_completion_from_url</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-78">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-79">            <span class="p">{</span>
</span><span id="line-80">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-81">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-82">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this image?"</span><span class="p">},</span>
</span><span id="line-83">                    <span class="p">{</span>
</span><span id="line-84">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"image_url"</span><span class="p">,</span>
</span><span id="line-85">                        <span class="s2">"image_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="n">image_url</span><span class="p">},</span>
</span><span id="line-86">                    <span class="p">},</span>
</span><span id="line-87">                <span class="p">],</span>
</span><span id="line-88">            <span class="p">}</span>
</span><span id="line-89">        <span class="p">],</span>
</span><span id="line-90">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-91">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-92">    <span class="p">)</span>
</span><span id="line-93">
</span><span id="line-94">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_url</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-95">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from image url:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-96">
</span><span id="line-97">    <span class="c1">## Use base64 encoded image in the payload</span>
</span><span id="line-98">    <span class="n">image_base64</span> <span class="o">=</span> <span class="n">encode_base64_content_from_url</span><span class="p">(</span><span class="n">image_url</span><span class="p">)</span>
</span><span id="line-99">    <span class="n">chat_completion_from_base64</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-100">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-101">            <span class="p">{</span>
</span><span id="line-102">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-103">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-104">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this image?"</span><span class="p">},</span>
</span><span id="line-105">                    <span class="p">{</span>
</span><span id="line-106">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"image_url"</span><span class="p">,</span>
</span><span id="line-107">                        <span class="s2">"image_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"data:image/jpeg;base64,</span><span class="si">{</span><span class="n">image_base64</span><span class="si">}</span><span class="s2">"</span><span class="p">},</span>
</span><span id="line-108">                    <span class="p">},</span>
</span><span id="line-109">                <span class="p">],</span>
</span><span id="line-110">            <span class="p">}</span>
</span><span id="line-111">        <span class="p">],</span>
</span><span id="line-112">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-113">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-114">    <span class="p">)</span>
</span><span id="line-115">
</span><span id="line-116">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_base64</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-117">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from base64 encoded image:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-118">
</span><span id="line-119">
</span><span id="line-120"><span class="c1"># Multi-image input inference</span>
</span><span id="line-121"><span class="k">def</span><span class="w"> </span><span class="nf">run_multi_image</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-122">    <span class="n">image_url_duck</span> <span class="o">=</span> <span class="s2">"https://upload.wikimedia.org/wikipedia/commons/d/da/2015_Kaczka_krzy%C5%BCowka_w_wodzie_</span><span class="si">%28s</span><span class="s2">amiec%29.jpg"</span>
</span><span id="line-123">    <span class="n">image_url_lion</span> <span class="o">=</span> <span class="s2">"https://upload.wikimedia.org/wikipedia/commons/7/77/002_The_lion_king_Snyggve_in_the_Serengeti_National_Park_Photo_by_Giles_Laurent.jpg"</span>
</span><span id="line-124">    <span class="n">chat_completion_from_url</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-125">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-126">            <span class="p">{</span>
</span><span id="line-127">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-128">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-129">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What are the animals in these images?"</span><span class="p">},</span>
</span><span id="line-130">                    <span class="p">{</span>
</span><span id="line-131">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"image_url"</span><span class="p">,</span>
</span><span id="line-132">                        <span class="s2">"image_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="n">image_url_duck</span><span class="p">},</span>
</span><span id="line-133">                    <span class="p">},</span>
</span><span id="line-134">                    <span class="p">{</span>
</span><span id="line-135">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"image_url"</span><span class="p">,</span>
</span><span id="line-136">                        <span class="s2">"image_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="n">image_url_lion</span><span class="p">},</span>
</span><span id="line-137">                    <span class="p">},</span>
</span><span id="line-138">                <span class="p">],</span>
</span><span id="line-139">            <span class="p">}</span>
</span><span id="line-140">        <span class="p">],</span>
</span><span id="line-141">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-142">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-143">    <span class="p">)</span>
</span><span id="line-144">
</span><span id="line-145">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_url</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-146">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-147">
</span><span id="line-148">
</span><span id="line-149"><span class="c1"># Video input inference</span>
</span><span id="line-150"><span class="k">def</span><span class="w"> </span><span class="nf">run_video</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-151">    <span class="n">video_url</span> <span class="o">=</span> <span class="s2">"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerFun.mp4"</span>
</span><span id="line-152">    <span class="n">video_base64</span> <span class="o">=</span> <span class="n">encode_base64_content_from_url</span><span class="p">(</span><span class="n">video_url</span><span class="p">)</span>
</span><span id="line-153">
</span><span id="line-154">    <span class="c1">## Use video url in the payload</span>
</span><span id="line-155">    <span class="n">chat_completion_from_url</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-156">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-157">            <span class="p">{</span>
</span><span id="line-158">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-159">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-160">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this video?"</span><span class="p">},</span>
</span><span id="line-161">                    <span class="p">{</span>
</span><span id="line-162">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"video_url"</span><span class="p">,</span>
</span><span id="line-163">                        <span class="s2">"video_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="n">video_url</span><span class="p">},</span>
</span><span id="line-164">                    <span class="p">},</span>
</span><span id="line-165">                <span class="p">],</span>
</span><span id="line-166">            <span class="p">}</span>
</span><span id="line-167">        <span class="p">],</span>
</span><span id="line-168">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-169">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-170">    <span class="p">)</span>
</span><span id="line-171">
</span><span id="line-172">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_url</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-173">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from image url:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-174">
</span><span id="line-175">    <span class="c1">## Use base64 encoded video in the payload</span>
</span><span id="line-176">    <span class="n">chat_completion_from_base64</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-177">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-178">            <span class="p">{</span>
</span><span id="line-179">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-180">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-181">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this video?"</span><span class="p">},</span>
</span><span id="line-182">                    <span class="p">{</span>
</span><span id="line-183">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"video_url"</span><span class="p">,</span>
</span><span id="line-184">                        <span class="s2">"video_url"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"data:video/mp4;base64,</span><span class="si">{</span><span class="n">video_base64</span><span class="si">}</span><span class="s2">"</span><span class="p">},</span>
</span><span id="line-185">                    <span class="p">},</span>
</span><span id="line-186">                <span class="p">],</span>
</span><span id="line-187">            <span class="p">}</span>
</span><span id="line-188">        <span class="p">],</span>
</span><span id="line-189">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-190">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-191">    <span class="p">)</span>
</span><span id="line-192">
</span><span id="line-193">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_base64</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-194">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from base64 encoded image:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-195">
</span><span id="line-196">
</span><span id="line-197"><span class="c1"># Audio input inference</span>
</span><span id="line-198"><span class="k">def</span><span class="w"> </span><span class="nf">run_audio</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-199">    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.assets.audio</span><span class="w"> </span><span class="kn">import</span> <span class="n">AudioAsset</span>
</span><span id="line-200">
</span><span id="line-201">    <span class="n">audio_url</span> <span class="o">=</span> <span class="n">AudioAsset</span><span class="p">(</span><span class="s2">"winning_call"</span><span class="p">)</span><span class="o">.</span><span class="n">url</span>
</span><span id="line-202">    <span class="n">audio_base64</span> <span class="o">=</span> <span class="n">encode_base64_content_from_url</span><span class="p">(</span><span class="n">audio_url</span><span class="p">)</span>
</span><span id="line-203">
</span><span id="line-204">    <span class="c1"># OpenAI-compatible schema (`input_audio`)</span>
</span><span id="line-205">    <span class="n">chat_completion_from_base64</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-206">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-207">            <span class="p">{</span>
</span><span id="line-208">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-209">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-210">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this audio?"</span><span class="p">},</span>
</span><span id="line-211">                    <span class="p">{</span>
</span><span id="line-212">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"input_audio"</span><span class="p">,</span>
</span><span id="line-213">                        <span class="s2">"input_audio"</span><span class="p">:</span> <span class="p">{</span>
</span><span id="line-214">                            <span class="c1"># Any format supported by librosa is supported</span>
</span><span id="line-215">                            <span class="s2">"data"</span><span class="p">:</span> <span class="n">audio_base64</span><span class="p">,</span>
</span><span id="line-216">                            <span class="s2">"format"</span><span class="p">:</span> <span class="s2">"wav"</span><span class="p">,</span>
</span><span id="line-217">                        <span class="p">},</span>
</span><span id="line-218">                    <span class="p">},</span>
</span><span id="line-219">                <span class="p">],</span>
</span><span id="line-220">            <span class="p">}</span>
</span><span id="line-221">        <span class="p">],</span>
</span><span id="line-222">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-223">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-224">    <span class="p">)</span>
</span><span id="line-225">
</span><span id="line-226">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_base64</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-227">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from input audio:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-228">
</span><span id="line-229">    <span class="c1"># HTTP URL</span>
</span><span id="line-230">    <span class="n">chat_completion_from_url</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-231">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-232">            <span class="p">{</span>
</span><span id="line-233">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-234">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-235">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this audio?"</span><span class="p">},</span>
</span><span id="line-236">                    <span class="p">{</span>
</span><span id="line-237">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"audio_url"</span><span class="p">,</span>
</span><span id="line-238">                        <span class="s2">"audio_url"</span><span class="p">:</span> <span class="p">{</span>
</span><span id="line-239">                            <span class="c1"># Any format supported by librosa is supported</span>
</span><span id="line-240">                            <span class="s2">"url"</span><span class="p">:</span> <span class="n">audio_url</span>
</span><span id="line-241">                        <span class="p">},</span>
</span><span id="line-242">                    <span class="p">},</span>
</span><span id="line-243">                <span class="p">],</span>
</span><span id="line-244">            <span class="p">}</span>
</span><span id="line-245">        <span class="p">],</span>
</span><span id="line-246">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-247">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-248">    <span class="p">)</span>
</span><span id="line-249">
</span><span id="line-250">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_url</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-251">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from audio url:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-252">
</span><span id="line-253">    <span class="c1"># base64 URL</span>
</span><span id="line-254">    <span class="n">chat_completion_from_base64</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-255">        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="line-256">            <span class="p">{</span>
</span><span id="line-257">                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="line-258">                <span class="s2">"content"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="line-259">                    <span class="p">{</span><span class="s2">"type"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"What's in this audio?"</span><span class="p">},</span>
</span><span id="line-260">                    <span class="p">{</span>
</span><span id="line-261">                        <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"audio_url"</span><span class="p">,</span>
</span><span id="line-262">                        <span class="s2">"audio_url"</span><span class="p">:</span> <span class="p">{</span>
</span><span id="line-263">                            <span class="c1"># Any format supported by librosa is supported</span>
</span><span id="line-264">                            <span class="s2">"url"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"data:audio/ogg;base64,</span><span class="si">{</span><span class="n">audio_base64</span><span class="si">}</span><span class="s2">"</span>
</span><span id="line-265">                        <span class="p">},</span>
</span><span id="line-266">                    <span class="p">},</span>
</span><span id="line-267">                <span class="p">],</span>
</span><span id="line-268">            <span class="p">}</span>
</span><span id="line-269">        <span class="p">],</span>
</span><span id="line-270">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-271">        <span class="n">max_completion_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-272">    <span class="p">)</span>
</span><span id="line-273">
</span><span id="line-274">    <span class="n">result</span> <span class="o">=</span> <span class="n">chat_completion_from_base64</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-275">    <span class="nb">print</span><span class="p">(</span><span class="s2">"Chat completion output from base64 encoded audio:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</span><span id="line-276">
</span><span id="line-277">
</span><span id="line-278"><span class="n">example_function_map</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-279">    <span class="s2">"text-only"</span><span class="p">:</span> <span class="n">run_text_only</span><span class="p">,</span>
</span><span id="line-280">    <span class="s2">"single-image"</span><span class="p">:</span> <span class="n">run_single_image</span><span class="p">,</span>
</span><span id="line-281">    <span class="s2">"multi-image"</span><span class="p">:</span> <span class="n">run_multi_image</span><span class="p">,</span>
</span><span id="line-282">    <span class="s2">"video"</span><span class="p">:</span> <span class="n">run_video</span><span class="p">,</span>
</span><span id="line-283">    <span class="s2">"audio"</span><span class="p">:</span> <span class="n">run_audio</span><span class="p">,</span>
</span><span id="line-284"><span class="p">}</span>
</span><span id="line-285">
</span><span id="line-286">
</span><span id="line-287"><span class="k">def</span><span class="w"> </span><span class="nf">parse_args</span><span class="p">():</span>
</span><span id="line-288">    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">(</span>
</span><span id="line-289">        <span class="n">description</span><span class="o">=</span><span class="s2">"Demo on using OpenAI client for online serving with "</span>
</span><span id="line-290">        <span class="s2">"multimodal language models served with vLLM."</span>
</span><span id="line-291">    <span class="p">)</span>
</span><span id="line-292">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="line-293">        <span class="s2">"--chat-type"</span><span class="p">,</span>
</span><span id="line-294">        <span class="s2">"-c"</span><span class="p">,</span>
</span><span id="line-295">        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="line-296">        <span class="n">default</span><span class="o">=</span><span class="s2">"single-image"</span><span class="p">,</span>
</span><span id="line-297">        <span class="n">choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">example_function_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span>
</span><span id="line-298">        <span class="n">help</span><span class="o">=</span><span class="s2">"Conversation type with multimodal data."</span><span class="p">,</span>
</span><span id="line-299">    <span class="p">)</span>
</span><span id="line-300">    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span><span id="line-301">
</span><span id="line-302">
</span><span id="line-303"><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-304">    <span class="n">chat_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">chat_type</span>
</span><span id="line-305">    <span class="n">model</span> <span class="o">=</span> <span class="n">get_first_model</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
</span><span id="line-306">    <span class="n">example_function_map</span><span class="p">[</span><span class="n">chat_type</span><span class="p">](</span><span class="n">model</span><span class="p">)</span>
</span><span id="line-307">
</span><span id="line-308">
</span><span id="line-309"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
</span><span id="line-310">    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
</span><span id="line-311">    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-312">    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</span><span id="line-313">    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-314">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Time taken: </span><span class="si">{</span><span class="n">end_time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</section>
</section>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="dynamic_connector.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        vLLM Dynamic Connector
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="../community/meetings.html">
        Community meetings
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#overview'" class="reference internal" href="#overview">Overview</a><ul>
<li><a :data-current="activeSection === '#examples-of-ttft-speed-up-for-different-multimodal-types'" class="reference internal" href="#examples-of-ttft-speed-up-for-different-multimodal-types">Examples of TTFT speed up for different multimodal types</a><ul>
<li><a :data-current="activeSection === '#prerequisites'" class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a :data-current="activeSection === '#examples'" class="reference internal" href="#examples">Examples</a><ul>
<li><a :data-current="activeSection === '#audio-inference-with-ultravox'" class="reference internal" href="#audio-inference-with-ultravox">Audio Inference with Ultravox:</a></li>
<li><a :data-current="activeSection === '#single-image-inference-with-llava'" class="reference internal" href="#single-image-inference-with-llava">Single Image Inference with Llava:</a></li>
<li><a :data-current="activeSection === '#multi-image-inference-with-phi-3-5-vision-instruct'" class="reference internal" href="#multi-image-inference-with-phi-3-5-vision-instruct">Multi-image Inference with Phi-3.5-vision-instruct:</a></li>
<li><a :data-current="activeSection === '#video-inference-with-llava-onevision'" class="reference internal" href="#video-inference-with-llava-onevision">Video Inference with Llava-OneVision:</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#id1'" class="reference internal" href="#id1">Example output</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#reference-inferencing-multimodal-models-in-vllm-example-python-script'" class="reference internal" href="#reference-inferencing-multimodal-models-in-vllm-example-python-script">Reference: Inferencing multimodal models in vLLM example Python script</a></li>
</ul>
</li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Â© 2024, The LMCache TeamÂ Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.2.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../_static/doctools.js?v=9bcbadda"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=073f68d9"></script>
<script src="../_static/sphinxcontrib-images/LightBox2/lightbox2/dist/js/lightbox-plus-jquery.min.js?v=f0ca4bb6"></script>
<script src="../_static/sphinxcontrib-images/LightBox2/lightbox2-customize/jquery-noconflict.js?v=12818e64"></script>
<script src="../_static/custom.js?v=e5cd2227"></script>
</body>
</html>