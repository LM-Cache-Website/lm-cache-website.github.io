<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Example: Offload KV cache to CPU | LMCache</title>
<meta content="Example: Offload KV cache to CPU | LMCache" property="og:title"/>
<meta content="Example: Offload KV cache to CPU | LMCache" name="twitter:title"/>
<link href="../../_static/pygments.css?v=935426dd" rel="stylesheet" type="text/css"/>
<link href="../../_static/theme.css?v=42baaae4" rel="stylesheet" type="text/css"/>
<link href="../../_static/custom.css?v=0f06b6ab" rel="stylesheet" type="text/css"/>
<link href="../../_static/scroll.css?v=d15ffde1" rel="stylesheet" type="text/css"/>
<link href="../../_static/lmcache-logo.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="share_kv_cache.html" rel="next" title="Example: Share KV cache across multiple LLMs"/>
<link href="index.html" rel="prev" title="Quickstart Examples"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">LMCache</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/LMCache/LMCache/" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223                 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412                 -3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232                  3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474                 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24                  44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" aria-label="Color theme switcher" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../../index.html"><span class="font-bold text-clip whitespace-nowrap">LMCache</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Welcome to LMCache</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Welcome to LMCache!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="index.html">Quickstart Examples<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul class="current" x-show="expanded">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Example: Offload KV cache to CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="share_kv_cache.html">Example: Share KV cache across multiple LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="disaggregated_prefill.html">Example: Disaggregated prefill</a></li>
<li class="toctree-l2"><a class="reference internal" href="multimodality.html">Example: Multimodal KV Cache Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshoot.html">TroubleShoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache offloading and sharing</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../kv_cache/storage_backends/index.html">Using Different Storage Backends<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/cpu_ram.html">CPU RAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/local_storage.html">Local storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/gds.html">GDS Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/redis.html">Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/s3.html">S3 Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/infinistore.html">InfiniStore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/mooncake.html">Mooncake</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/valkey.html">ValKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/weka.html">Weka</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/nixl.html">Nixl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache/storage_backends/external_backend.html">External Storage Backends</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../kv_cache/caching_policies.html">Using Different Caching Policies</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Disaggregated prefill</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../disaggregated_prefill/nixl/index.html">Using NIXL<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../disaggregated_prefill/nixl/1p1d.html">1p1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../disaggregated_prefill/nixl/xpyd.html">XpYd</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../disaggregated_prefill/shared_storage.html">Using shared storage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache management</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../kv_cache_management/index.html">LMCache Controller<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/clear.html">Clear the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/compress.html">Compress and Decompress the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/health.html">Check controller health</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/lookup.html">Lookup the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/move.html">Move the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/pin.html">Pin the KV cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_management/check_finish.html">Check finish of a control event</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV Cache Optimizations</span></p>
<ul>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../kv_cache_optimizations/compression/index.html">Compression<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../kv_cache_optimizations/compression/cachegen.html">CacheGen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../kv_cache_optimizations/blending.html">Blending</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use LMCache in production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../production/docker_deployment.html">Docker deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../production/kubernetes_deployment.html">Kubernetes deployment</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../production/observability/index.html">Observability<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../production/observability/vllm_endpoint.html">Metrics by vLLM API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../production/observability/internal_api_server.html">Internal API Server Metrics</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internal API Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../internal_api_server/internal_api_server.html">Configuring the Internal API Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal_api_server/internal_api_server.html#how-to-extend-the-internal-api-server">How to extend the Internal API Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/docker_file.html">Dockerfile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/architecture.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide/integration.html">Integration</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../developer_guide/extending_lmcache/index.html">Extending LMCache<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../developer_guide/extending_lmcache/plugin.html">Extending LMCache: Plugin</a></li>
</ul>
</li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../developer_guide/usage/index.html">Usage Data Module<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../developer_guide/usage/usage_stats_collection.html">Usage Stats Collection</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/configurations.html">Configuring LMCache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/storage_backends.html">Adding new storage backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/dynamic_connector.html">vLLM Dynamic Connector</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/multimodality.html">KV Caching for Multimodal Models with vLLM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/meetings.html">Community meetings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/blogs.html">Blogs</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../../index.html">
<span class="hidden md:inline">LMCache</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap" href="index.html">Quickstart Examples</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Example: Offload KV cache to CPU</span>
</nav>
<div id="content" role="main">
<section id="example-offload-kv-cache-to-cpu">
<span id="offload-kv-cache"></span><h1>Example: Offload KV cache to CPU<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#example-offload-kv-cache-to-cpu"><span>#</span></a></h1>
<p>In this example, we will show you how to offload KV cache to CPU memory.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Besides CPU memory, LMCache also supports offloading KV cache to many different destinations.
See <a class="reference internal" href="#supported-offloading-destinations"><span class="std std-ref">Supported offloading destinations</span></a> for more details.</p>
</div>
<section id="prerequisites">
<h2>Prerequisites<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#prerequisites" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#prerequisites'"><span>#</span></a></h2>
<p>Before you begin, make sure you have:</p>
<ul class="simple">
<li><p>vLLM v1 with LMCache installed (see <a class="reference internal" href="../installation.html"><span class="doc">Installation</span></a>)</p></li>
<li><p>A GPU that can run a LLM</p></li>
</ul>
</section>
<section id="use-cpu-offloading-in-offline-inference">
<h2>Use CPU offloading in offline inference<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#use-cpu-offloading-in-offline-inference" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#use-cpu-offloading-in-offline-inference'"><span>#</span></a></h2>
<p>This section demonstrates how to use CPU memory offloading in offline inference scenarios using LMCache with vLLM.
The example script we use here is available in <a class="reference external" href="https://github.com/vllm-project/vllm/blob/main/examples/others/lmcache/cpu_offload_lmcache.py">vLLM examples</a>.
See the <a class="reference external" href="https://github.com/vllm-project/vllm/tree/main/examples/others/lmcache#2-cpu-offload-examples">examples README</a> to understand how to run the script for vLLM v1.</p>
<p>First, set up the necessary environment variables for LMCache:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="line-2">
</span><span id="line-3"><span class="c1"># Set token chunk size to 256</span>
</span><span id="line-4"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"LMCACHE_CHUNK_SIZE"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"256"</span>
</span><span id="line-5"><span class="c1"># Enable CPU memory backend</span>
</span><span id="line-6"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"LMCACHE_LOCAL_CPU"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"True"</span>
</span><span id="line-7"><span class="c1"># Set CPU memory limit to 5GB</span>
</span><span id="line-8"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"LMCACHE_MAX_LOCAL_CPU_SIZE"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"5.0"</span>
</span></code></pre></div>
</div>
<p>Next, configure vLLM with LMCache integration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="line-2"><span class="kn">from</span><span class="w"> </span><span class="nn">vllm.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">KVTransferConfig</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># Configure KV cache transfer to use LMCache</span>
</span><span id="line-5"><span class="n">ktc</span> <span class="o">=</span> <span class="n">KVTransferConfig</span><span class="p">(</span>
</span><span id="line-6">    <span class="n">kv_connector</span><span class="o">=</span><span class="s2">"LMCacheConnectorV1"</span><span class="p">,</span>
</span><span id="line-7">    <span class="n">kv_role</span><span class="o">=</span><span class="s2">"kv_both"</span><span class="p">,</span>
</span><span id="line-8"><span class="p">)</span>
</span><span id="line-9">
</span><span id="line-10"><span class="c1"># Initialize LLM with LMCache configuration</span>
</span><span id="line-11"><span class="c1"># Adjust gpu_memory_utilization based on your GPU memory</span>
</span><span id="line-12"><span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"Qwen/Qwen3-8B"</span><span class="p">,</span>
</span><span id="line-13">          <span class="n">kv_transfer_config</span><span class="o">=</span><span class="n">ktc</span><span class="p">,</span>
</span><span id="line-14">          <span class="n">max_model_len</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span>
</span><span id="line-15">          <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>Now you can run inference with automatic KV cache offloading:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># Create example prompts with shared prefix</span>
</span><span id="line-2"><span class="n">shared_prompt</span> <span class="o">=</span> <span class="s2">"Hello, how are you?"</span> <span class="o">*</span> <span class="mi">1000</span>
</span><span id="line-3"><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="line-4">    <span class="n">shared_prompt</span> <span class="o">+</span> <span class="s2">"Hello, my name is"</span><span class="p">,</span>
</span><span id="line-5"><span class="p">]</span>
</span><span id="line-6">
</span><span id="line-7"><span class="c1"># Define sampling parameters</span>
</span><span id="line-8"><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="line-9">
</span><span id="line-10"><span class="c1"># Run inference</span>
</span><span id="line-11"><span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="line-12"><span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
</span><span id="line-13">    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</span><span id="line-14">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>When the inference is complete, clean up the LMCache backend:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">from</span><span class="w"> </span><span class="nn">lmcache.v1.cache_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">LMCacheEngineBuilder</span>
</span><span id="line-2"><span class="kn">from</span><span class="w"> </span><span class="nn">lmcache.integration.vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">ENGINE_NAME</span>
</span><span id="line-3">
</span><span id="line-4"><span class="n">LMCacheEngineBuilder</span><span class="o">.</span><span class="n">destroy</span><span class="p">(</span><span class="n">ENGINE_NAME</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>During inference, LMCache will automatically handle storing and managing KV cache in CPU memory. You can monitor this through the logs, which will show messages like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">LMCache</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Storing</span> <span class="n">KV</span> <span class="n">cache</span> <span class="k">for</span> <span class="mi">6006</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">6006</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">request</span> <span class="mi">0</span>
</span></code></pre></div>
</div>
<p>This indicates that the KV cache has been successfully offloaded to CPU memory.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Adjust <code class="docutils literal notranslate"><span class="pre">gpu_memory_utilization</span></code> based on your GPU’s available memory</p></li>
<li><p>The CPU offloading buffer size can be adjusted through <code class="docutils literal notranslate"><span class="pre">LMCACHE_MAX_LOCAL_CPU_SIZE</span></code></p></li>
</ul>
</div>
</section>
<section id="use-cpu-offloading-in-online-inference">
<h2>Use CPU offloading in online inference<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#use-cpu-offloading-in-online-inference" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#use-cpu-offloading-in-online-inference'"><span>#</span></a></h2>
<p>This section demonstrates how to use CPU memory offloading in online serving scenarios.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>LMCache supports extensive configuration through a <code class="docutils literal notranslate"><span class="pre">lmcache_config.yaml</span></code> file where you can customize chunk sizes, memory limits, storage backends, and more. We’ll cover advanced configuration options in later examples. For now, let’s run a minimal example with default configuration.</p>
</div>
<p>Launch the vLLM server with LMCache integration using environment variables. Here’s an example command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">vllm<span class="w"> </span>serve<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">    </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
</span><span id="line-3"><span class="w">    </span>--kv-transfer-config<span class="w"> </span><span class="se">\</span>
</span><span id="line-4"><span class="w">    </span><span class="s1">'{"kv_connector":"LMCacheConnectorV1",</span>
</span><span id="line-5"><span class="s1">      "kv_role":"kv_both"</span>
</span><span id="line-6"><span class="s1">    }'</span>
</span></code></pre></div>
</div>
<p>Key parameters explained:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LMCACHE_CONFIG_FILE</span></code>: Path to the LMCache configuration file.</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">--kv-transfer-config</span></code>: Configures LMCache integration</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">kv_connector</span></code>: Specifies the LMCache connector</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kv_role</span></code>: Set to “kv_both” for both storing and loading KV cache</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Once the server is running, you can send requests to it using curl. Here’s an example of how to send a request to the vLLM server with LMCache integration:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">curl<span class="w"> </span>http://localhost:8000/v1/completions<span class="w"> </span><span class="se">\</span>
</span><span id="line-2"><span class="w">  </span>-H<span class="w"> </span><span class="s2">"Content-Type: application/json"</span><span class="w"> </span><span class="se">\</span>
</span><span id="line-3"><span class="w">  </span>-d<span class="w"> </span><span class="s1">'{</span>
</span><span id="line-4"><span class="s1">    "model": "Qwen/Qwen3-8B",</span>
</span><span id="line-5"><span class="s1">    "prompt": "&lt;|im_start|&gt;system\nYou are a helpful AI assistant.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nWhat is the capital of France?&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n",</span>
</span><span id="line-6"><span class="s1">    "max_tokens": 100,</span>
</span><span id="line-7"><span class="s1">    "temperature": 0.7</span>
</span><span id="line-8"><span class="s1">  }'</span>
</span></code></pre></div>
</div>
<p>You should see the following logs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><mark>LMCache INFO: Storing KV cache for 31 out of 31 tokens for request cmpl-274bcaa80837444dbf9fbba4155d2620-0 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
</mark></span></code></pre></div>
</div>
<p>Once you send the same curl request again, you should see the following logs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><mark>LMCache INFO: Reqid: cmpl-4ddf8863a6ac4dc3b6a952f2a107e9b2-0, Total tokens 31, LMCache hit tokens: 30, need to load: 14 (vllm_v1_adapter.py:543:lmcache.integration.vllm.vllm_v1_adapter)
</mark></span></code></pre></div>
</div>
</section>
<section id="example-cpu-offloading-benefits">
<h2>Example: CPU offloading benefits<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#example-cpu-offloading-benefits" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#example-cpu-offloading-benefits'"><span>#</span></a></h2>
<p>This section demonstrates the performance benefits of using CPU offloading with LMCache. We’ll use a script that generates multiple prompts and compare the performance with and without LMCache.</p>
<section id="prerequisites-setup">
<h3>Prerequisites (Setup)<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#prerequisites-setup" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#prerequisites-setup'"><span>#</span></a></h3>
<ul class="simple">
<li><p>At least 24GB GPU memory</p></li>
<li><p>Sufficient CPU memory (LMCache will use 15 GB by default in this example).</p></li>
</ul>
</section>
<section id="example-script">
<h3>Example script<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#example-script" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#example-script'"><span>#</span></a></h3>
<p>Save the following script as <code class="docutils literal notranslate"><span class="pre">cpu-offloading.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
</span><span id="line-2"><span class="sd">"""</span>
</span><span id="line-3"><span class="sd">This file demonstrates the example usage of cpu offloading</span>
</span><span id="line-4"><span class="sd">with LMCache in vLLM v1.</span>
</span><span id="line-5">
</span><span id="line-6"><span class="sd">Note that lmcache needs to be installed to run this example.</span>
</span><span id="line-7"><span class="sd">Learn more about LMCache in https://github.com/LMCache/LMCache.</span>
</span><span id="line-8"><span class="sd">"""</span>
</span><span id="line-9"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="line-10"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-11"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span id="line-12"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="line-13"><span class="kn">from</span><span class="w"> </span><span class="nn">lmcache.v1.cache_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">LMCacheEngineBuilder</span>
</span><span id="line-14"><span class="kn">from</span><span class="w"> </span><span class="nn">lmcache.integration.vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">ENGINE_NAME</span>
</span><span id="line-15"><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="line-16"><span class="kn">from</span><span class="w"> </span><span class="nn">vllm.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">KVTransferConfig</span>
</span><span id="line-17">
</span><span id="line-18"><span class="k">def</span><span class="w"> </span><span class="nf">parse_arguments</span><span class="p">():</span>
</span><span id="line-19"><span class="w">    </span><span class="sd">"""Parse command line arguments."""</span>
</span><span id="line-20">    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"CPU offloading example with LMCache"</span><span class="p">)</span>
</span><span id="line-21">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--num-prompts"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="line-22">                      <span class="n">help</span><span class="o">=</span><span class="s2">"Number of prompts to generate (default: 10)"</span><span class="p">)</span>
</span><span id="line-23">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--num-tokens"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
</span><span id="line-24">                      <span class="n">help</span><span class="o">=</span><span class="s2">"Number of tokens per prompt (default: 10000)"</span><span class="p">)</span>
</span><span id="line-25">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">"--enable-lmcache"</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">"store_true"</span><span class="p">,</span>
</span><span id="line-26">                      <span class="n">help</span><span class="o">=</span><span class="s2">"Enable LMCache for CPU offloading (default: True)"</span><span class="p">)</span>
</span><span id="line-27">    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span><span id="line-28">
</span><span id="line-29"><span class="k">def</span><span class="w"> </span><span class="nf">setup_lmcache_environment</span><span class="p">(</span><span class="n">num_prompts</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">):</span>
</span><span id="line-30"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-31"><span class="sd">    Configure LMCache environment variables.</span>
</span><span id="line-32"><span class="sd">    Args:</span>
</span><span id="line-33"><span class="sd">        num_prompts: Number of prompts to process</span>
</span><span id="line-34"><span class="sd">        num_tokens: Number of tokens per prompt</span>
</span><span id="line-35"><span class="sd">    """</span>
</span><span id="line-36">    <span class="n">cpu_size</span> <span class="o">=</span> <span class="n">num_prompts</span> <span class="o">*</span> <span class="n">num_tokens</span> <span class="o">*</span> <span class="mf">1.5</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="c1"># 1.5GB per 10000 tokens</span>
</span><span id="line-37">
</span><span id="line-38">    <span class="n">env_vars</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-39">        <span class="s2">"LMCACHE_CHUNK_SIZE"</span><span class="p">:</span> <span class="s2">"256"</span><span class="p">,</span>         <span class="c1"># Set tokens per chunk</span>
</span><span id="line-40">        <span class="s2">"LMCACHE_LOCAL_CPU"</span><span class="p">:</span> <span class="s2">"True"</span><span class="p">,</span>         <span class="c1"># Enable local CPU backend</span>
</span><span id="line-41">        <span class="s2">"LMCACHE_MAX_LOCAL_CPU_SIZE"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">cpu_size</span><span class="p">)</span>  <span class="c1"># Dynamic CPU memory limit (GB)</span>
</span><span id="line-42">    <span class="p">}</span>
</span><span id="line-43">    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">env_vars</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="line-44">        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="line-45">
</span><span id="line-46"><span class="k">def</span><span class="w"> </span><span class="nf">calculate_gpu_utilization</span><span class="p">(</span><span class="n">target_memory_gb</span><span class="o">=</span><span class="mi">24</span><span class="p">):</span>
</span><span id="line-47"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-48"><span class="sd">    Calculate GPU memory utilization to use exactly target_memory_gb of GPU memory.</span>
</span><span id="line-49"><span class="sd">    Args:</span>
</span><span id="line-50"><span class="sd">        target_memory_gb: Target GPU memory usage in gigabytes</span>
</span><span id="line-51"><span class="sd">    Returns:</span>
</span><span id="line-52"><span class="sd">        float: GPU memory utilization ratio (0.0 to 1.0)</span>
</span><span id="line-53"><span class="sd">    Raises:</span>
</span><span id="line-54"><span class="sd">        RuntimeError: If GPU memory is less than target_memory_gb</span>
</span><span id="line-55"><span class="sd">    """</span>
</span><span id="line-56">    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="line-57">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"No GPU available"</span><span class="p">)</span>
</span><span id="line-58">
</span><span id="line-59">    <span class="n">total_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Convert to GB</span>
</span><span id="line-60">    <span class="k">if</span> <span class="n">total_memory</span> <span class="o">&lt;</span> <span class="n">target_memory_gb</span><span class="p">:</span>
</span><span id="line-61">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"GPU memory (</span><span class="si">{</span><span class="n">total_memory</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB) is less than required memory (</span><span class="si">{</span><span class="n">target_memory_gb</span><span class="si">}</span><span class="s2">GB)"</span><span class="p">)</span>
</span><span id="line-62">
</span><span id="line-63">    <span class="k">return</span> <span class="n">target_memory_gb</span> <span class="o">/</span> <span class="n">total_memory</span>
</span><span id="line-64">
</span><span id="line-65"><span class="k">def</span><span class="w"> </span><span class="nf">create_test_prompts</span><span class="p">(</span><span class="n">num_prompts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span><span id="line-66"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-67"><span class="sd">    Create test prompts with index prefix and dummy body.</span>
</span><span id="line-68"><span class="sd">    Args:</span>
</span><span id="line-69"><span class="sd">        num_prompts: Number of prompts to generate</span>
</span><span id="line-70"><span class="sd">        num_tokens: Approximate number of tokens per prompt (using 'Hi ' as token unit)</span>
</span><span id="line-71"><span class="sd">    Returns:</span>
</span><span id="line-72"><span class="sd">        list: List of prompts with format '[index] Hi Hi Hi...'</span>
</span><span id="line-73"><span class="sd">    """</span>
</span><span id="line-74">    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-75">    <span class="n">dummy_text</span> <span class="o">=</span> <span class="s2">"Hi "</span> <span class="o">*</span> <span class="n">num_tokens</span>
</span><span id="line-76">
</span><span id="line-77">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_prompts</span><span class="p">):</span>
</span><span id="line-78">        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"[Prompt </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">dummy_text</span><span class="si">}</span><span class="s2"> how are you?"</span>
</span><span id="line-79">        <span class="n">prompts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="line-80">
</span><span id="line-81">    <span class="k">return</span> <span class="n">prompts</span>
</span><span id="line-82">
</span><span id="line-83"><span class="k">def</span><span class="w"> </span><span class="nf">initialize_llm</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">"Qwen/Qwen3-8B"</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">16384</span><span class="p">,</span> <span class="n">enable_lmcache</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="line-84"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-85"><span class="sd">    Initialize the LLM with appropriate configurations.</span>
</span><span id="line-86"><span class="sd">    Args:</span>
</span><span id="line-87"><span class="sd">        model_name: Name of the model to load</span>
</span><span id="line-88"><span class="sd">        max_len: Maximum sequence length</span>
</span><span id="line-89"><span class="sd">    Returns:</span>
</span><span id="line-90"><span class="sd">        LLM: Configured LLM instance</span>
</span><span id="line-91"><span class="sd">    """</span>
</span><span id="line-92">    <span class="n">ktc</span> <span class="o">=</span> <span class="n">KVTransferConfig</span><span class="p">(</span>
</span><span id="line-93">        <span class="n">kv_connector</span><span class="o">=</span><span class="s2">"LMCacheConnectorV1"</span><span class="p">,</span>
</span><span id="line-94">        <span class="n">kv_role</span><span class="o">=</span><span class="s2">"kv_both"</span><span class="p">,</span>
</span><span id="line-95">    <span class="p">)</span> <span class="k">if</span> <span class="n">enable_lmcache</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="line-96">
</span><span id="line-97">    <span class="k">return</span> <span class="n">LLM</span><span class="p">(</span>
</span><span id="line-98">        <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="line-99">        <span class="n">kv_transfer_config</span><span class="o">=</span><span class="n">ktc</span><span class="p">,</span>
</span><span id="line-100">        <span class="n">max_model_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
</span><span id="line-101">        <span class="n">enable_prefix_caching</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="line-102">        <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="n">calculate_gpu_utilization</span><span class="p">()</span>
</span><span id="line-103">    <span class="p">)</span>
</span><span id="line-104">
</span><span id="line-105"><span class="k">def</span><span class="w"> </span><span class="nf">generate_and_print_output</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">):</span>
</span><span id="line-106"><span class="w">    </span><span class="sd">"""</span>
</span><span id="line-107"><span class="sd">    Generate text and print the results.</span>
</span><span id="line-108"><span class="sd">    Args:</span>
</span><span id="line-109"><span class="sd">        llm: LLM instance</span>
</span><span id="line-110"><span class="sd">        prompts: List of input prompts</span>
</span><span id="line-111"><span class="sd">        sampling_params: Configured sampling parameters</span>
</span><span id="line-112"><span class="sd">    Returns:</span>
</span><span id="line-113"><span class="sd">        float: Time taken for generation in seconds</span>
</span><span id="line-114"><span class="sd">    """</span>
</span><span id="line-115">    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-116">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="line-117">    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-118">
</span><span id="line-119">    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
</span><span id="line-120">        <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</span><span id="line-121">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="line-122">
</span><span id="line-123">    <span class="k">return</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
</span><span id="line-124">
</span><span id="line-125"><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="line-126"><span class="w">    </span><span class="sd">"""Main execution function."""</span>
</span><span id="line-127">    <span class="c1"># Parse command line arguments</span>
</span><span id="line-128">    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_arguments</span><span class="p">()</span>
</span><span id="line-129">
</span><span id="line-130">    <span class="c1"># Setup environment if LMCache is enabled</span>
</span><span id="line-131">    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">enable_lmcache</span><span class="p">:</span>
</span><span id="line-132">        <span class="n">setup_lmcache_environment</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_prompts</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_tokens</span><span class="p">)</span>
</span><span id="line-133">
</span><span id="line-134">    <span class="c1"># Create prompts and sampling parameters</span>
</span><span id="line-135">    <span class="n">prompts</span> <span class="o">=</span> <span class="n">create_test_prompts</span><span class="p">(</span><span class="n">num_prompts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_prompts</span><span class="p">,</span> <span class="n">num_tokens</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_tokens</span><span class="p">)</span>
</span><span id="line-136">    <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-137">
</span><span id="line-138">    <span class="c1"># Initialize model</span>
</span><span id="line-139">    <span class="n">llm</span> <span class="o">=</span> <span class="n">initialize_llm</span><span class="p">(</span><span class="n">enable_lmcache</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">enable_lmcache</span><span class="p">)</span>
</span><span id="line-140">
</span><span id="line-141">    <span class="c1"># First run</span>
</span><span id="line-142">    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">First run:"</span><span class="p">)</span>
</span><span id="line-143">    <span class="n">first_run_time</span> <span class="o">=</span> <span class="n">generate_and_print_output</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="line-144">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First run time: </span><span class="si">{</span><span class="n">first_run_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</span><span id="line-145">
</span><span id="line-146">    <span class="c1"># Second run</span>
</span><span id="line-147">    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Second run:"</span><span class="p">)</span>
</span><span id="line-148">    <span class="n">second_run_time</span> <span class="o">=</span> <span class="n">generate_and_print_output</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="line-149">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Second run time: </span><span class="si">{</span><span class="n">second_run_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</span><span id="line-150">
</span><span id="line-151">    <span class="c1"># Print speedup</span>
</span><span id="line-152">    <span class="k">if</span> <span class="n">first_run_time</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="line-153">        <span class="n">speedup</span> <span class="o">=</span> <span class="n">first_run_time</span> <span class="o">/</span> <span class="n">second_run_time</span>
</span><span id="line-154">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Speedup (first run / second run): </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x"</span><span class="p">)</span>
</span><span id="line-155">
</span><span id="line-156">    <span class="c1"># Cleanup if LMCache was enabled</span>
</span><span id="line-157">    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">enable_lmcache</span><span class="p">:</span>
</span><span id="line-158">        <span class="n">LMCacheEngineBuilder</span><span class="o">.</span><span class="n">destroy</span><span class="p">(</span><span class="n">ENGINE_NAME</span><span class="p">)</span>
</span><span id="line-159">
</span><span id="line-160"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
</span><span id="line-161">    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
</div>
</section>
<section id="running-the-example">
<h3>Running the Example<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#running-the-example" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#running-the-example'"><span>#</span></a></h3>
<ol class="arabic">
<li><p>First, run the script without LMCache:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">python<span class="w"> </span>cpu-offloading.py
</span></code></pre></div>
</div>
<p>You’ll see output like:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Speedup (first run / second run): 1.00x
</span></code></pre></div>
</div>
<p>Without LMCache, there’s no speedup between runs even if vLLM has prefix caching enabled.
This is because the KV cache exceeds GPU memory and can’t be reused.</p>
</li>
<li><p>Now, run with LMCache enabled:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">python<span class="w"> </span>cpu-offloading.py<span class="w"> </span>--enable-lmcache
</span></code></pre></div>
</div>
<p>You’ll see output like:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><code><span id="line-1">Speedup (first run / second run): 7.43x
</span></code></pre></div>
</div>
</li>
</ol>
<p>The significant speedup in the second case demonstrates how LMCache effectively manages KV cache offloading to CPU memory.
When the total size of KV cache exceeds GPU memory, LMCache allows you to store and reuse the cache from CPU memory,
resulting in much faster subsequent generations for prompts with shared prefixes.</p>
</section>
</section>
<section id="supported-offloading-destinations">
<h2>Supported offloading destinations<a @click.prevent="window.navigator.clipboard.writeText($el.href); $el.setAttribute('data-tooltip', 'Copied!'); setTimeout(() =&gt; $el.setAttribute('data-tooltip', 'Copy link to this element'), 2000)" aria-label="Copy link to this element" class="headerlink" data-tooltip="Copy link to this element" href="#supported-offloading-destinations" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#supported-offloading-destinations'"><span>#</span></a></h2>
<p>LMCache now supports offloading KV cache to the following destinations:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/cpu_ram.html"><span class="doc">CPU memory</span></a></p></li>
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/local_storage.html"><span class="doc">Local file system</span></a></p></li>
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/mooncake.html"><span class="doc">Mooncake Storage</span></a></p></li>
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/infinistore.html"><span class="doc">InfiniStore</span></a></p></li>
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/redis.html"><span class="doc">Redis</span></a></p></li>
<li><p><a class="reference internal" href="../../kv_cache/storage_backends/valkey.html"><span class="doc">ValKey</span></a></p></li>
</ul>
</section>
</section>
</div><div class="flex justify-between items-center pt-6 mt-12 border-t border-border gap-4">
<div class="mr-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="index.html">
<svg class="mr-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="15 18 9 12 15 6"></polyline>
</svg>
        Quickstart Examples
      </a>
</div>
<div class="ml-auto">
<a class="inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors border border-input hover:bg-accent hover:text-accent-foreground py-2 px-4" href="share_kv_cache.html">
        Example: Share KV cache across multiple LLMs
        <svg class="ml-2 h-4 w-4" fill="none" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<polyline points="9 18 15 12 9 6"></polyline>
</svg>
</a>
</div>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#prerequisites'" class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a :data-current="activeSection === '#use-cpu-offloading-in-offline-inference'" class="reference internal" href="#use-cpu-offloading-in-offline-inference">Use CPU offloading in offline inference</a></li>
<li><a :data-current="activeSection === '#use-cpu-offloading-in-online-inference'" class="reference internal" href="#use-cpu-offloading-in-online-inference">Use CPU offloading in online inference</a></li>
<li><a :data-current="activeSection === '#example-cpu-offloading-benefits'" class="reference internal" href="#example-cpu-offloading-benefits">Example: CPU offloading benefits</a><ul>
<li><a :data-current="activeSection === '#prerequisites-setup'" class="reference internal" href="#prerequisites-setup">Prerequisites (Setup)</a></li>
<li><a :data-current="activeSection === '#example-script'" class="reference internal" href="#example-script">Example script</a></li>
<li><a :data-current="activeSection === '#running-the-example'" class="reference internal" href="#running-the-example">Running the Example</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#supported-offloading-destinations'" class="reference internal" href="#supported-offloading-destinations">Supported offloading destinations</a></li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2024, The LMCache Team Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.2.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../../_static/doctools.js?v=9bcbadda"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../../_static/theme.js?v=073f68d9"></script>
</body>
</html>